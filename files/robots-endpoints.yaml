id: robots-txt-endpoints
info:
  name: enumerate robots.txt file for endpoints
  author: CasperGN
  severity: info

# We need no space between GET and {{endpoint}} since the regex matches a space followed by / (e.g. (?m:(\s/... below. Hence the match contains the space)
# as of now, this only issues for the first match on below extractor.
# TODO: Figure out a way to reuse the request
requests:
  - raw:
      - |
        GET /robots.txt HTTP/1.1
        Host: {{Hostname}}
        User-Agent: Mozilla/5.0 (X11; Fedora; Linux x86_64; rv:80.0) Gecko/20100101 Firefox/80.0
        Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
        Accept-Language: en-US,en;q=0.5
      - |
        GET{{endpoint}} HTTP/1.1
        Host: {{Hostname}}
        User-Agent: Mozilla/5.0 (X11; Fedora; Linux x86_64; rv:80.0) Gecko/20100101 Firefox/80.0
        Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
        Accept-Language: en-US,en;q=0.5

    extractors:
      - type: regex
        name: endpoint
        part: body
        internal: true
        regex:
          - '(?m:(\s/[[:alpha:]]+[[:graph:]]+))'

    matchers:
      - type: status
        status:
          - 200
          - 301
          - 302
          - 303
          - 401
          - 403
          - 405
